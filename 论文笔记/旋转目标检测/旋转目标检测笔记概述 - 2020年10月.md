# 旋转目标检测

**本次旋转目标检测的笔记是针对即将进行的火箭军AI大赛科目四做的相关调研，总结了截止2020年10月以来，在遥感图像的小目标、密集、任意方向下的旋转目标检测方法，以及当前已有方法下仍旧存在的问题。**如有纰误，敬请指正。

<div align="center">
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201010184443353.png" alt="img" width=350 />
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201010184451186.png" alt="img" width=350 />
</div>

<br>

## 一、笔记介绍

* 目前目标检测的工作集中在三个方面：**水平区域目标检测（Horizontal region object detection），任意方向目标检测（Arbitrary-oriented object detection），方位信息分类（Classification for orientation information）**。**水平区域目标检测**即为经典的目标检测方法，旨在利用常规水平框检测图像的目标，如`FasterRCNN`，`YOLO`，`SSD`是常见的**Anchor-based**的方法，而`CenterNet`，`CornerNet`则是**Anchor-free**的方法；**任意方向目标检测**则是希望对任意方向上的目标能够用一个四边形的框更准确的表示物体的范围，主流的方法可分为三种：基于旋转候选框的五参数法、基于候选框顶点偏移的八参数法和基于极坐标角度回归的五参数法。常见Baseline有`ICN`，`	ROI-Transformer`，`SCRDet`，`R3Det`等方法。最后一种**方位信息分类**的方法则是用于诸如人脸方向检测等，不在该笔记的讨论之内。
* 遥感旋转检测研究比文字晚一些，目前也有方法是从文字检测中迁移过来，但个人认为如果从旋转框角度来做的话，遥感可能会更难一些。毕竟文字是单类别，很多方法都是提出有针对性的tricks，而遥感更需要考虑不同物体的类别，直接放到遥感就不适用。遥感的旋转目标检测需要考虑更general的思路，其难点主要包括小目标 （small objects）、密集 （cluttered arrangement）、方向任意（arbitrary orientations）。

* 根据已有的旋转目标检测的代表性方法（不完全统计，更多统计的点击**第5.1节的链接[3]**），按照是否基于Anchor，单/两阶段，参数类型进行分类：

  |       Model        |   Backbone   |                          Paper Link                          | Stage  |    Anchor    |                          Parameters                          |
  | :----------------: | :----------: | :----------------------------------------------------------: | :----: | :----------: | :----------------------------------------------------------: |
  |  R<sup>3</sup>Det  |  ResNet152   |        [HRSC 2016](https://arxiv.org/abs/1908.05612)         | Single | Anchor-based |                   5-Params: Center+(w,h)+θ                   |
  |  R<sup>2</sup>CNN  |  ResNet101   |        [CVPR 2017](https://arxiv.org/abs/1706.09579)         |  Two   | Anchor-based | 5-Params: (x<sub>1</sub>,y<sub>1</sub>,x<sub>2</sub>,y<sub>2</sub>,h) |
  |       SCRDet       |  ResNet101   | [ICCV 2019](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_SCRDet_Towards_More_Robust_Detection_for_Small_Cluttered_and_Rotated_ICCV_2019_paper.pdf) |  Two   | Anchor-based |                   5-Params: Center+(w,h)+θ                   |
  |   Gliding Vertex   |  ResNet101   |  [TPAMI 2019](https://ieeexplore.ieee.org/document/9001201)  | Single | Anchor-free  | 8-Params: Center+(w,h)+(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,a<sub>4</sub>) |
  |      P-RSDet       |  ResNet101   |     [arXiv:2001.02988](https://arxiv.org/abs/2001.02988)     | Single | Anchor-free  |    5-Params: Center+*ρ*+(*θ<sub>1</sub>*,*θ<sub>2</sub>*)    |
  | O<sup>2</sup>-DNet | Hourglass104 |     [arXiv:1912.10694](https://arxiv.org/abs/1912.10694)     | Single | Anchor-free  | 8-Params: Center+(Δx<sub>1</sub>,Δx<sub>2</sub>,Δy<sub>1</sub>,Δy<sub>2</sub>) |
  |     BBAVector      |  ResNet101   |        [WACV 2020](https://arxiv.org/abs/2008.07043)         | Single | Anchor-free  |      12-Params: Center+(**t**,**r**,**l**,**b**)+(w,h)       |

<br>

## 二、旋转目标检测

本节主要介绍旋转目标检测中较为主流和创新性的旋转框定义和预测方法，当然定义方式并不局限于这几种，但是殊途同归，很多不同的表示方式都基于相似的思想并存在相同的问题。

### 2.1 Center+(w,h)+θ 五参数法

Center+(w,h)+θ 五参数法经典的方法有`RRPN`，`ROI-Transformer`，`R2CNN`，`R3Det`等，目前有两种主流表示方法：OpenCV法（a）和长边表示法（b）。

* OpenCV表示法（a），回归角度为-90到0度：
  * 沿**水平方向**定义参考线，位于该参考线上垂直坐标最小的顶点作为参考原点
  * **逆时针旋转**参考线，参考线接触的第一个矩形边定义为**宽度w**，而与该边垂直的另一条边定义为**高度h**
  * 旋转矩形框的中心点坐标为（x，y），旋转角度为 θ， θ∈[-90, 0]
* 长边表示法（b），回归角度为-90度到90度：
  * 沿**水平方向**定义参考线，选取矩形框的一个**最长边h**，并以该边水平方向最小的顶点作为参考原点
  * 角度 θ 为**长边h**与水平方向的**x轴**所形成的夹角，因此角度的范围是 θ∈[-90, 90]

<div align="center">
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201010084120280.png" alt="img" width=500 />
</div>

虽然这两种表示方式在实际遥感和文字的旋转目标检测应用中取得了比较出色的成果，但是由于大长宽比的目标、训练的损失对于角度的变化和边交换是非常敏感的，因此这两种表示方法都存在**回归难度大**、**损失不连续**、**回归边界模糊**，**度量单位（量纲）不一致**的问题。

#### 回归难度大

回归难度大体现在，由角度的周期性（**PoA**）和边的可交换性（**EoE**）导致**理想的回归路线的损失很大**（也就是在实际训练过程中，模型走了弯路）。YangXue在[SCRDet ICCV2019](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_SCRDet_Towards_More_Robust_Detection_for_Small_Cluttered_and_Rotated_ICCV_2019_paper.pdf)以及[CSL ECCV 2020](http://arxiv.org/abs/2003.05597)中均有提出：

>loss of this situation is very large due to the periodicity of angular (PoA) and exchangeability of edges (EoE)  

<div align="center">
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201011104752008.png" alt="img" width=800 />
</div>

* 基于90°回归的方法，如上图（a）所示。蓝色框、红色框和绿色框分别是参考候选框，预测框和真实框，**特别注意这几个框的长h和宽w所在的位置！！**最理想的角度回归路线是由参考候选框（蓝色）逆时针旋转得到预测框（红色），预测框（红色）和真实框（绿色）便可以基本重合。但是模型并不会将hw进行交换（矩形框存在边的可交换性**EoE**），导致理想的回归的损失非常大。因此实际训练过程中，模型会迫使参考候选框顺时针旋转到灰色框的等效位置（角度的周期性**PoA**）并缩放长宽，从而加大了回归的难度。（按照我个人的理解：角度的周期性PoA应该描述为**角度的等效性**更加合适）
* 基于180°回归的方法，即长边表示法，如上图（b）所示，该方法避免了矩形框的边的可交换性的问题，但是类似地，该方法也存在由边界处的PoA引起的损损失剧增的问题。 该模型最终将参考候选框顺时针旋转一个大角度，以获得最终的预测边界框。**（注意这里图有错误：蓝色候选框，绿色真实框，红色预测框的角度应该分别是π/2，5π/8，3π/8**）

#### 损失不连续

* 
* ，但由于角度的周期性，导致按照这个回归方式的损失非常大（参见上图右边的示例）
* 
* 理想的回归形式是候选框（蓝色）相对于预测框
* 
* 
* 首先先验假设为：三个框的中心点在（0，0）点，候选框的旋转角度为-90°，
* 
* 
* 预测框（红色）是相对于参考框（蓝色，θ = -90°）
* 
* 它显示了一种理想的回归形式（蓝色框相对于红色框逆时针旋转），但是由于角度的周期性（PoA）和边的可交换性（EoE），这种情况的损失非常大，请参见示例 图3（a）和公式3、4、5的详细信息。 因此，必须以其他复杂形式对模型进行回归（例如，缩放w和h时，将蓝色框顺时针旋转到灰色框），从而增加了回归的难度。
* 基于180°回归的方法，如图（b）所示。 类似地，该方法也存在由边界处的PoA引起的损耗急剧增加的问题。 该模型最终将选择将投标顺时针旋转一个大角度，以获得最终的预测边界框。





**问：对于(a)中，predict box的参数是(0,0,100,25, -5pi/8)，这是红色虚线框的几何参数吗？按照前面的定义，此时红色虚线框的w和h应该更接近(25,100)?角度也更接近-pi/8吧？**

>预测框是根据候选框的中心点平移，长宽缩放，角度旋转回归得到的。所以预测出来的框并不一定和你定义的表示形式是一致的，这才导致的边界问题的出现。就如你自己发现的，红框的定义应该是0 0 25 100 -pi/8，但是预测的话模型不会自动把蓝框的wh交换，也不知道角度有周期性-5pi/8和-pi/8两个角度是重合的。模型只知道把候选框的参数进行加减乘除，是不是超过定义单位他是不知道的，我们一般的水平检测的坐标参数取值是没有范围界限的，所以也没有这样的问题。





RRPN应该是第一个基于RPN架构引入旋转候选框实现任意方向的场景文本检测。基于旋转的anchor得到旋转ROI，然后提取相应特征。



### 2.2 Center+(Δx<sub>1</sub>,Δx<sub>2</sub>,Δy<sub>1</sub>,Δy<sub>2</sub>) 八参数法





我认为他的做法是牺牲了一定的预测精度（通过水平框来近似）来逃避了边界预测不好的问题，但是确实也是有一定效果的。另外，边界问题是否真的是它认为的那样也是模糊的？





### 2.3 Center+*ρ*+(*θ<sub>1</sub>*,*θ<sub>2</sub>*) 极坐标五参数法





### 2.4 Center+(**t**,**r**,**l**,**b**)+(w,h) 向量感知





#### (1) 量纲不一致

* Center+(w,h)+θ五参数法



>Moreover, in five-parameter system, parameters i.e. angle, width, height and center point have different measurement units, and show rather different relations against the Intersection over Union (IoU)   
>
><div align="center">
>    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201010090605328.png" alt="img" width=500 />
></div>





#### (2) 回归边界问题



#### (3) 损失不连续



<br>

## 三、方法总结





<br>

## 四、个人思考



<br>

## 五、参考资料

#### 5.1 相关链接

* ECCV2020｜遥感旋转目标检测方法解读：http://www.360doc.com/content/20/0708/21/32196507_923054270.shtml
* 知乎 | 遥感目标检测相关论文：https://zhuanlan.zhihu.com/p/98703562
* GITHUB | DOTA 数据集相关的代码库：https://github.com/SJTU-Thinklab-Det/DOTA-DOAI
* 上交大牛 YangXue | 遥感目标检测个人论文说明：https://www.zhihu.com/people/flyyoung-68/posts

#### 5.2 参考论文

* [1] Yang X , Yan J . **Arbitrary-Oriented Object Detection with Circular Smooth Label**. *ECCV*. 2020.
* [2] Zhou X, Wang D, Krähenbühl P. **CenterNet: Objects as points**. *CVPR*. 2019.
* [3] Qian W, Yang X, Peng S, et al. **RSDet: Learning modulated loss for rotated object detection**. *CVPR*. 2019.
* [4] Yang X, Yang J, Yan J, et al. **SCRDet: Towards more robust detection for small, cluttered and rotated objects**. *CVPR*. 2019.
* [5] Xu Y, Fu M, Wang Q, et al. **Gliding Vertex: Gliding vertex on the horizontal bounding box for multi-oriented object detection**. *TPAMI*. 2020.
* [6] Zhou L, Wei H, Li H, et al. **O<sup>2</sup>-DNet: Objects detection for remote sensing images based on polar coordinates**. *arXiv:2001.02988*. 2020.
* [7] Wei H, Zhou L, Zhang Y, et al. **P-RSDet: Oriented objects as pairs of middle lines**. *arXiv:1912.10694*. 2019.
* [8] Yi J, Wu P, Liu B, et al. **BBAVector: Oriented Object Detection in Aerial Images with Box Boundary-Aware Vectors**. *WACV*. 2020.

<br>