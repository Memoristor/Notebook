# 旋转目标检测

**本次旋转目标检测的笔记是针对即将进行的火箭军AI大赛科目四做的相关调研，总结了截止2020年10月以来，在遥感图像的小目标、密集、任意方向下的旋转目标检测方法，以及当前已有方法下仍旧存在的问题。**如有纰误，敬请指正。

<div align="center">
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201010184443353.png" alt="img" width=350 />
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201010184451186.png" alt="img" width=350 />
</div>

<br>

## 一、笔记介绍

* 目前目标检测的工作集中在三个方面：**水平区域目标检测（Horizontal region object detection），任意方向目标检测（Arbitrary-oriented object detection），方位信息分类（Classification for orientation information）**。**水平区域目标检测**即为经典的目标检测方法，旨在利用常规水平框检测图像的目标，如`FasterRCNN`，`YOLO`，`SSD`是常见的**Anchor-based**的方法，而`CenterNet`，`CornerNet`则是**Anchor-free**的方法；**任意方向目标检测**则是希望对任意方向上的目标能够用一个四边形的框更准确的表示物体的范围，主流的方法可分为三种：基于旋转候选框的五参数法、基于候选框顶点偏移的八参数法和基于极坐标角度回归的五参数法。常见Baseline有`ICN`，`	ROI-Transformer`，`SCRDet`，`R3Det`等方法。最后一种**方位信息分类**的方法则是用于诸如人脸方向检测等，不在该笔记的讨论之内。
* 遥感旋转检测研究比文字晚一些，目前也有方法是从文字检测中迁移过来，但个人认为如果从旋转框角度来做的话，遥感可能会更难一些。毕竟文字是单类别，很多方法都是提出有针对性的tricks，而遥感更需要考虑不同物体的类别，直接放到遥感就不适用。遥感的旋转目标检测需要考虑更general的思路，其难点主要包括小目标 （small objects）、密集 （cluttered arrangement）、方向任意（arbitrary orientations）。

* 根据已有的旋转目标检测的代表性方法（不完全统计，更多统计的点击**第5.1节的链接[3]**），按照是否基于Anchor，单/两阶段，参数类型进行分类：

  |       Model        |   Backbone   |                          Paper Link                          | Stage  |    Anchor    |                          Parameters                          |
  | :----------------: | :----------: | :----------------------------------------------------------: | :----: | :----------: | :----------------------------------------------------------: |
  |  R<sup>3</sup>Det  |  ResNet152   |        [HRSC 2016](https://arxiv.org/abs/1908.05612)         | Single | Anchor-based |                   5-Params: Center+(w,h)+θ                   |
  |  R<sup>2</sup>CNN  |  ResNet101   |        [CVPR 2017](https://arxiv.org/abs/1706.09579)         |  Two   | Anchor-based | 5-Params: (x<sub>1</sub>,y<sub>1</sub>,x<sub>2</sub>,y<sub>2</sub>,h) |
  |       SCRDet       |  ResNet101   | [ICCV 2019](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_SCRDet_Towards_More_Robust_Detection_for_Small_Cluttered_and_Rotated_ICCV_2019_paper.pdf) |  Two   | Anchor-based |                   5-Params: Center+(w,h)+θ                   |
  |   Gliding Vertex   |  ResNet101   |  [TPAMI 2019](https://ieeexplore.ieee.org/document/9001201)  | Single | Anchor-free  | 8-Params: Center+(w,h)+(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,a<sub>4</sub>) |
  |      P-RSDet       |  ResNet101   |     [arXiv:2001.02988](https://arxiv.org/abs/2001.02988)     | Single | Anchor-free  |    5-Params: Center+*ρ*+(*θ<sub>1</sub>*,*θ<sub>2</sub>*)    |
  | O<sup>2</sup>-DNet | Hourglass104 |     [arXiv:1912.10694](https://arxiv.org/abs/1912.10694)     | Single | Anchor-free  | 8-Params: 2x(Δx<sub>1</sub>,Δx<sub>2</sub>,Δy<sub>1</sub>,Δy<sub>2</sub>) |
  |     BBAVector      |  ResNet101   |        [WACV 2020](https://arxiv.org/abs/2008.07043)         | Single | Anchor-free  |      12-Params: Center+(**t**,**r**,**l**,**b**)+(w,h)       |

<br>

## 二、预测参数的定义

本节主要介绍旋转目标检测中较为主流和创新性的旋转框定义和预测方法，当然定义方式并不局限于这几种，但是殊途同归，很多不同的表示方式都基于相似的思想并存在相同的问题。

### 2.1 Center+(w,h)+θ 五参数法

Center+(w,h)+θ 五参数法经典的方法有`RRPN`，`ROI-Transformer`，`R2CNN`，`R3Det`等，目前有两种主流表示方法：OpenCV法（a）和长边表示法（b）。

* OpenCV表示法（a），回归角度为-90到0度：
  * 沿**水平方向**定义参考线，位于该参考线上垂直坐标最小的顶点作为参考原点
  * **逆时针旋转**参考线，参考线接触的第一个矩形边定义为**宽度w**，而与该边垂直的另一条边定义为**高度h**
  * 旋转矩形框的中心点坐标为（x，y），旋转角度为 θ， θ∈[-90, 0]
* 长边表示法（b），回归角度为-90度到90度：
  * 沿**水平方向**定义参考线，选取矩形框的一个**最长边h**，并以该边水平方向最小的顶点作为参考原点
  * 角度 θ 为**长边h**与水平方向的**x轴**所形成的夹角，因此角度的范围是 θ∈[-90, 90]

<div align="center">
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201010084120280.png" alt="img" width=500 />
</div>

虽然这两种表示方式在实际遥感和文字的旋转目标检测应用中取得了比较出色的成果，但是由于大长宽比的目标、训练的损失对于角度的变化和边交换是非常敏感的，因此这两种表示方法都存在**回归难度大**、**损失不连续**、**回归边界模糊**，**度量单位（量纲）不一致**的问题。

### 2.2 Center+(w,h)+(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,a<sub>4</sub>) 八参数法

Center+(w,h)+(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,a<sub>4</sub>) 八参数法需要在训练前对四边形框的四个点按照一定规则进行排序。首先了解一下为什么要排序：如果一个四边形的ground-truth是（x1,y1,x2,y2,x3,y3,x4,y4）并且所有的ground-truth并不是按一定规则顺序标注的，那么检测器有可能给出的预测结果是（x2,y2,x3,y3,x4,y4,x1,y1）。其实这两个是框是完全重合的，但是网络训练算损失的时候并不知道，它会按对应位置计算损失，此时的损失值并不为0甚至很大。而Center+(w,h)+(a<sub>1</sub>,a<sub>2</sub>,a<sub>3</sub>,a<sub>4</sub>)八参数法则考虑到了顺序标签点（sequential label points）的问题。

<div align="center">
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201011232343294.png" alt="img" width=500 />
</div>

基于上述问题，[Gliding Vertex](https://ieeexplore.ieee.org/document/9001201)通过改变框的表示方式避免了排序的麻烦：

> By limiting the offset on the corresponding side of horizontal bounding box, we may facilitate offset learning and also avoid the confusion for sequential label points in directly regressing the four vertices of oriented objects. 

先检测水平框，这个是没有序列问题的，然后**学习水平框四个角点的偏移量**来达到四边形检测的目的，其实这里的（偏移量，对应的水平框的点）配对就有排序的意思了。相比较而言，RSDet则是对角点进行了排序（对ground-truth的排序并不耗时，对检测器影响几乎忽略不计），并给出了一种角点的排序算法：其主要步骤是先确定最左边的点（如果水平矩形的话有两个点满足取上面的那个）。然后通过[叉乘（向量积）](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%90%91%E9%87%8F%E7%A7%AF/4601007%3Ffr%3Daladdin)找到对角点，也就是第三个点。最后利用这两个点构成的向量以及叉乘方法，根据顺序的要求（逆时针或者顺时针）找点其他两个点

### 2.3 Center+*ρ*+(*θ<sub>1</sub>*,*θ<sub>2</sub>*) 极坐标五参数法





### 2.4 Center+(**t**,**r**,**l**,**b**)+(w,h) 向量感知



在2.1节中定义的五参数法，使用旋转边界框进行检测，角度预测的准确性至关重要，较小的角度偏差即可导致IoU下降，从而导致目标检测不准确，而且如果。而

## 三、存在的问题

### 3.1 回归难度大

回归难度大体现在，由角度的周期性（**PoA**）和边的可交换性（**EoE**）导致**理想的回归路线的损失很大**（也就是在实际训练过程中，模型走了弯路）。YangXue在[SCRDet ICCV2019](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_SCRDet_Towards_More_Robust_Detection_for_Small_Cluttered_and_Rotated_ICCV_2019_paper.pdf)以及[CSL ECCV 2020](http://arxiv.org/abs/2003.05597)中均有提出：

>loss of this situation is very large due to the periodicity of angular (PoA) and exchangeability of edges (EoE)  

<div align="center">
    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201011104752008.png" alt="img" width=800 />
</div>

* 基于90°回归的方法，如上图（a）所示。蓝色框、红色框和绿色框分别是参考候选框，预测框和真实框，**特别注意这几个框的长h和宽w所在的位置！！**最理想的角度回归路线是由参考候选框（蓝色）逆时针旋转得到预测框（红色），预测框（红色）和真实框（绿色）便可以基本重合。但是模型并不会将hw进行交换（矩形框存在边的可交换性**EoE**），导致理想的回归的损失非常大。因此实际训练过程中，模型会迫使参考候选框顺时针旋转到灰色框的等效位置（角度的周期性**PoA**）并缩放长宽，从而加大了回归的难度。（按照我个人的理解：角度的周期性PoA应该描述为**角度的等效性**更加合适）
* 基于180°回归的方法，即长边表示法，如上图（b）所示，该方法避免了矩形框的边的可交换性的问题，但是类似地，该方法也存在由**PoA**引起的损损剧增的问题，即该模型最终将参考候选框顺时针旋转一个大角度，以获得最终的预测边界框。**（注意这里图有错误：蓝色候选框，绿色真实框，红色预测框的角度应该分别是π/2，5π/8，3π/8**）
* 原文对这里的叙述不是很清晰，尤其是图（b），







RRPN应该是第一个基于RPN架构引入旋转候选框实现任意方向的场景文本检测。基于旋转的anchor得到旋转ROI，然后提取相应特征。

### 3.2 损失不连续

### 3.3 回归边界模糊

### 3.4 度量单位（量纲）不一致





我认为他的做法是牺牲了一定的预测精度（通过水平框来近似）来逃避了边界预测不好的问题，但是确实也是有一定效果的。另外，边界问题是否真的是它认为的那样也是模糊的？







* Center+(w,h)+θ五参数法



>Moreover, in five-parameter system, parameters i.e. angle, width, height and center point have different measurement units, and show rather different relations against the Intersection over Union (IoU)   
>
><div align="center">
>    <img src="assets/旋转目标检测笔记概述 - 2020年10月/image-20201010090605328.png" alt="img" width=500 />
></div>







<br>

## 三、方法总结





<br>

## 四、个人思考



<br>

## 五、参考资料

#### 5.1 相关链接

* ECCV2020｜遥感旋转目标检测方法解读：http://www.360doc.com/content/20/0708/21/32196507_923054270.shtml
* 知乎 | 遥感目标检测相关论文：https://zhuanlan.zhihu.com/p/98703562
* GITHUB | DOTA 数据集相关的代码库：https://github.com/SJTU-Thinklab-Det/DOTA-DOAI
* 上交大牛 YangXue | 遥感目标检测个人论文说明：https://www.zhihu.com/people/flyyoung-68/posts

#### 5.2 参考论文

* [1] Yang X , Yan J . **Arbitrary-Oriented Object Detection with Circular Smooth Label**. *ECCV*. 2020.
* [2] Zhou X, Wang D, Krähenbühl P. **CenterNet: Objects as points**. *CVPR*. 2019.
* [3] Qian W, Yang X, Peng S, et al. **RSDet: Learning modulated loss for rotated object detection**. *CVPR*. 2019.
* [4] Yang X, Yang J, Yan J, et al. **SCRDet: Towards more robust detection for small, cluttered and rotated objects**. *CVPR*. 2019.
* [5] Xu Y, Fu M, Wang Q, et al. **Gliding Vertex: Gliding vertex on the horizontal bounding box for multi-oriented object detection**. *TPAMI*. 2020.
* [6] Zhou L, Wei H, Li H, et al. **O<sup>2</sup>-DNet: Objects detection for remote sensing images based on polar coordinates**. *arXiv:2001.02988*. 2020.
* [7] Wei H, Zhou L, Zhang Y, et al. **P-RSDet: Oriented objects as pairs of middle lines**. *arXiv:1912.10694*. 2019.
* [8] Yi J, Wu P, Liu B, et al. **BBAVector: Oriented Object Detection in Aerial Images with Box Boundary-Aware Vectors**. *WACV*. 2020.

<br>